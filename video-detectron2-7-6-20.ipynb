{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import key libraries\n",
    "from PIL import Image, ImageDraw\n",
    "import torch, torchvision\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import misc\n",
    "import scipy.ndimage\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_mp4_frames(link):\n",
    "    # create video capture instance\n",
    "    vidcap = cv2.VideoCapture(link)\n",
    "    success,image = vidcap.read()\n",
    "    frames = [image]\n",
    "    # iterate over video frames, save each in a list\n",
    "    while success:\n",
    "        success,image = vidcap.read()\n",
    "        frames.append(image)\n",
    "    return frames\n",
    "\n",
    "def create_predictor():\n",
    "    # create Detectron2 config and Default Predictor to run image inference\n",
    "    cfg = get_cfg()\n",
    "    # add project-specific config here if not running a model in Detectron2's core library\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "    cfg.MODEL.DEVICE = 'cpu'\n",
    "    # find a model from detectron2's model zoo.\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
    "    # build predictor\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "    return predictor\n",
    "\n",
    "def blur_people(img, predictor):\n",
    "    # image in tensor form\n",
    "    im = np.array(img)\n",
    "    # image dimensions\n",
    "    height, width, channels = im.shape\n",
    "    # run inference on the image\n",
    "    outputs = predictor(im)\n",
    "    # get indices of predicted instances that are labelled as people\n",
    "    person_idx = (outputs[\"instances\"].pred_classes==0)\n",
    "    # count of 'people' instances\n",
    "    person_count = np.sum(np.array(person_idx))\n",
    "    # get image masks corresponding to each identified person\n",
    "    person_masks_tensor = outputs[\"instances\"].pred_masks[person_idx,:,:]\n",
    "    # create PIL image masks\n",
    "    person_masks = Image.new('L', im.shape[:-1], 0)\n",
    "    draw = ImageDraw.Draw(person_masks)    \n",
    "    # create mask and add peoples' shape to it\n",
    "    sharp_mask = np.zeros((height, width, channels))\n",
    "    for i in range(person_count):\n",
    "        sharp_mask[person_masks_tensor[i,:,:]==1]=1\n",
    "    # filtered image\n",
    "    result = (np.multiply(filter_image(img),sharp_mask)+img).astype(dtype=np.uint8)            \n",
    "    return result\n",
    "\n",
    "def filter_image(sharp_image):\n",
    "    # does what it says on the tin\n",
    "    blurred_image = scipy.ndimage.filters.sobel(sharp_image, mode='constant')\n",
    "    blurred_image = scipy.ndimage.filters.prewitt(blurred_image, mode='reflect')\n",
    "    return blurred_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = r'/Users/julienraffaud/Downloads/IMG_0240.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = collect_mp4_frames(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use default detectron2 predictor\n",
    "predictor = create_predictor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.0% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.1% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.2% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.3% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.4% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.5% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.6% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.7% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.8% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "0.9% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n",
      "1.0% blurred\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-384feb5f27f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0;34m'%1.1f%% blurred'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mblurred_frames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblur_people\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredictor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-148-d61be3880f78>\u001b[0m in \u001b[0;36mblur_people\u001b[0;34m(img, predictor)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# image dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m# run inference on the image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "blurred_frames = []\n",
    "for i in range(len(frames)):\n",
    "    print ( '%1.2f%% blurred' %(i/len(frames)) )\n",
    "    blurred_frames.append(blur_people(frames[i],predictor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-220-ce70641dfa35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblurred_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblurred_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'/Users/julienraffaud/Desktop/Detection/Blurred_pics/blurred-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(len(blurred_frames)):\n",
    "    Image.fromarray(blurred_frames[i]).save(r'/Users/julienraffaud/Desktop/Detection/Blurred_pics/blurred-' + str(i)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "image_folder = r'/Users/julienraffaud/Desktop/Detection/Blurred_pics/'\n",
    "video_name = 'blurred_video.avi'\n",
    "\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".png\")]\n",
    "\n",
    "frame = cv2.imread(os.path.join(image_folder, images[0]))\n",
    "height, width, layers = (1920,1080,3)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v') \n",
    "video = cv2.VideoWriter(video_name, 0, 30, (width,height))\n",
    "\n",
    "for i in range(331):\n",
    "    img_name =  'blurred-%d.png' % i\n",
    "    video.write(cv2.imread(os.path.join(image_folder, img_name)))\n",
    "\n",
    "# for image in images:\n",
    "#     video.write(cv2.imread(os.path.join(image_folder, image)))\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
